{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainYolo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNCjmuwwTCQ1aOxU+v4ZgDv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baiyunming/I2DL_FinalProject/blob/main/TrainYolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oeh5Ppno8iaG"
      },
      "source": [
        "#**Import necessary packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH0HRQ94hPdp"
      },
      "source": [
        "import os\r\n",
        "import torch\r\n",
        "from google.colab import drive\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "import torch.optim as optim\r\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bi46v6q8yNe"
      },
      "source": [
        "#**Move to directory containing model.py, loss.py, animal_dataset.py, utils.py**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkDAyMtrhwM5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5ad1300-de21-40fa-c9a2-f27298c73d5e"
      },
      "source": [
        "drive.mount('/content/drive')\r\n",
        "%cd drive/MyDrive/ObjectDetection/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/ObjectDetection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7NNctag-igP"
      },
      "source": [
        "**import necessary classes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c78uflw3iDz4"
      },
      "source": [
        "from model import YOLO_Resnet\r\n",
        "from loss import YoloLoss\r\n",
        "from animal_dataset import AnimalDataset\r\n",
        "from utils import non_max_suppression, mean_average_precision, get_list_boxes, calculate_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCf8NIYn9YYQ"
      },
      "source": [
        "#**Dataset and dataloader**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZySGm5RBOiJ"
      },
      "source": [
        "**In order to create an inatance of class AnimalDataset, path to the csv file generated by Generate_txt_csv.ipynb is needed.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwiTXDQbk_Cs"
      },
      "source": [
        "train_dataset = AnimalDataset(\"/content/drive/MyDrive/ObjectDetection/animal_dataset/train_augmented.csv\")\r\n",
        "train_batch_size = 32\r\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\r\n",
        "\r\n",
        "valid_dataset = AnimalDataset(\"/content/drive/MyDrive/ObjectDetection/animal_dataset/test_augmented.csv\")\r\n",
        "valid_batch_size = 16\r\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=valid_batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz7VuVmS9km7"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1rky_nU-DiS"
      },
      "source": [
        "**Option 1: generate new model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAU0RxVLl6Fc"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
        "model = YOLO_Resnet().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABSGLAs9-kmc"
      },
      "source": [
        "**Option 2: load pretrained model (need to modify file_path to the corresponding path of the pretrained model) and you can directly skip to \"Visualization of result on validation(test) dataset\" part** \r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz8raqnoQRAi"
      },
      "source": [
        "#load pretrained model\r\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
        "file_path = \"./model1/best_model.pth\"\r\n",
        "checkpoint = torch.load(file_path)\r\n",
        "model = YOLO_Resnet()\r\n",
        "model.load_state_dict(checkpoint[\"state_dict\"]) \r\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBkQiICP-uk8"
      },
      "source": [
        "#**Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2kZ22TlnT9i"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=2e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-Flu0CE-z1k"
      },
      "source": [
        "# **Tensorboard for visualization of training process**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sOHDit9uUA0"
      },
      "source": [
        "# Load the TensorBoard notebook extension\r\n",
        "%load_ext tensorboard\r\n",
        "from tensorflow import summary\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0jKFgj1uOk_"
      },
      "source": [
        "train_log_dir = './run/train'\r\n",
        "train_summary_writer = summary.create_file_writer(train_log_dir)\r\n",
        "val_log_dir = './run/validate'\r\n",
        "val_summary_writer = summary.create_file_writer(val_log_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDVpOr1uuWHw"
      },
      "source": [
        "%tensorboard --logdir run"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaLmm20I-_nN"
      },
      "source": [
        "#**Define train and validate function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMhT42bdnVQU"
      },
      "source": [
        "def train(model, optimizer, image, label):\r\n",
        "    model.train()\r\n",
        "    batch_size = image.shape[0]\r\n",
        "\r\n",
        "    criterion = YoloLoss()\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    input = image.to(device)\r\n",
        "    target = label.to(device) \r\n",
        "    \r\n",
        "    pred = model(input)\r\n",
        "    loss = criterion(pred, target)/batch_size\r\n",
        "    \r\n",
        "    loss.backward()\r\n",
        "       \r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    return loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyyTC0TtvjQs"
      },
      "source": [
        "def validate(model, image, label):\r\n",
        "    model.eval()\r\n",
        "    batch_size = image.shape[0]\r\n",
        "\r\n",
        "    criterion = YoloLoss()\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "      input = image.to(device)\r\n",
        "      target = label.to(device) \r\n",
        "    \r\n",
        "      pred = model(input)\r\n",
        "      loss = criterion(pred, target)/batch_size\r\n",
        "\r\n",
        "    return loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNFiS_el_J_E"
      },
      "source": [
        "# **Start Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFKqFYoxpOf8"
      },
      "source": [
        "max_epoch = 50\r\n",
        "max_map = -1\r\n",
        "tmp_path = './checkpoint_model.pth'\r\n",
        "\r\n",
        "for epoch in tqdm(range(max_epoch)):\r\n",
        "    train_loss = 0 \r\n",
        "    train_map = 0\r\n",
        "    valid_loss = 0\r\n",
        "    valid_map = 0\r\n",
        "\r\n",
        "\r\n",
        "    # Iterate over the train_dataloader\r\n",
        "    with tqdm(total=len(train_dataloader)) as pbar:\r\n",
        "        for idx, [image, label, _] in enumerate(train_dataloader):\r\n",
        "          curr_loss = train(model, optimizer, image, label)\r\n",
        "          train_loss += curr_loss / len(train_dataloader)\r\n",
        "          pbar.update(1)\r\n",
        "\r\n",
        "    checkpoint = {\"state_dict\": model.state_dict(),\r\n",
        "            \"optimizer\": optimizer.state_dict(),}\r\n",
        "    torch.save(checkpoint, tmp_path)\r\n",
        "\r\n",
        "    train_map = calculate_map(model, train_dataloader, iou_threshold=0.4, confidence_threshold=0.5)\r\n",
        "    \r\n",
        "    with train_summary_writer.as_default():\r\n",
        "        tf.summary.scalar('loss', train_loss, step=epoch+80)                \r\n",
        "        tf.summary.scalar('map', train_map, step=epoch+80)     \r\n",
        "\r\n",
        "\r\n",
        "    with tqdm(total=len(valid_dataloader)) as pbar:\r\n",
        "        for idx, [image, label, _] in enumerate(valid_dataloader):\r\n",
        "          curr_loss = validate(model, image, label)\r\n",
        "          valid_loss += curr_loss / len(valid_dataloader)\r\n",
        "          pbar.update(1)\r\n",
        "\r\n",
        "    valid_map = calculate_map(model, valid_dataloader, iou_threshold=0.4, confidence_threshold=0.5)\r\n",
        "\r\n",
        "\r\n",
        "    with val_summary_writer.as_default():\r\n",
        "        tf.summary.scalar('loss', valid_loss, step=epoch+80)\r\n",
        "        tf.summary.scalar('map', valid_map, step=epoch+80) \r\n",
        "\r\n",
        "\r\n",
        "    max_map = max(valid_map, max_map)\r\n",
        "    if max_map == valid_map:\r\n",
        "      filename = './best_model.pth'\r\n",
        "      print(\"=> Saving checkpoint\")\r\n",
        "      torch.save(checkpoint, filename)\r\n",
        "\r\n",
        "\r\n",
        "    print(train_loss, valid_loss)\r\n",
        "    print(train_map, valid_map)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GcNFD-O_PZP"
      },
      "source": [
        "# **Visualization of result on validation(test) dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbvR9ahUsn7z"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.patches as patches\r\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkdWhDMf_bC9"
      },
      "source": [
        "**define function for plotting the bounding boxes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mhry5Ics1Dg"
      },
      "source": [
        "def plot_result(image_path, boxes):\r\n",
        "    \"\"\"Plots predicted bounding boxes on the image\"\"\"\r\n",
        "    im = Image.open(image_path)\r\n",
        "    width, height = im.size\r\n",
        "\r\n",
        "    # Create figure and axes\r\n",
        "    fig, ax = plt.subplots(1)\r\n",
        "    # Display the image\r\n",
        "    ax.imshow(im)\r\n",
        "\r\n",
        "    for box in bboxes:\r\n",
        "        pred_class_num = box[0]\r\n",
        "        score = box[1]\r\n",
        "        score = round(score, 2)\r\n",
        "        box = box[2:]\r\n",
        "        \r\n",
        "        if pred_class_num == 0:\r\n",
        "          pred_class = \"buffalo\"\r\n",
        "        elif pred_class_num == 1:\r\n",
        "          pred_class = \"elephant\"\r\n",
        "        elif pred_class_num == 2:\r\n",
        "          pred_class = \"rhino\"\r\n",
        "        else:\r\n",
        "          pred_class = \"zebra\"\r\n",
        "        \r\n",
        "        text = pred_class + \"(\" + str(score) + \")\"\r\n",
        "        #print(text)\r\n",
        "\r\n",
        "        assert len(box) == 4, \"Got more values than in x, y, w, h, in a box!\"\r\n",
        "        upper_left_x = box[0] - box[2] / 2\r\n",
        "        upper_left_y = box[1] - box[3] / 2\r\n",
        "        rect = patches.Rectangle(\r\n",
        "            (upper_left_x * width, upper_left_y * height),\r\n",
        "            box[2] * width,\r\n",
        "            box[3] * height,\r\n",
        "            linewidth=1,\r\n",
        "            edgecolor=\"r\",\r\n",
        "            facecolor=\"none\",\r\n",
        "        )\r\n",
        "        # Add the patch to the Axes\r\n",
        "        ax.text(upper_left_x*width, upper_left_y*height, text, bbox=dict(facecolor='red', alpha=0.5))\r\n",
        "        ax.add_patch(rect)\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-4zH9Er_jUe"
      },
      "source": [
        "**plot result on all validation(test) images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cyDxRC7DsHQX",
        "outputId": "2066d5bc-9ee1-4cef-d238-f8d38818c5ec"
      },
      "source": [
        "for x, y, path in valid_dataloader:\r\n",
        "  with torch.no_grad():\r\n",
        "    x = x.to(device)\r\n",
        "    for idx in range(x.shape[0]):\r\n",
        "      bboxes = get_list_boxes(model(x), S=5)\r\n",
        "      bboxes = non_max_suppression(bboxes[idx], 0.5, 0.5)\r\n",
        "      #print(bboxes)\r\n",
        "      #print(path[idx])\r\n",
        "      #print(\"show_result\")\r\n",
        "      plot_result(path[idx], bboxes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnZjuU6bAHQb"
      },
      "source": [
        "# **Calculate MAP for different iou_thresholds**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw9RMPGV2Rwy"
      },
      "source": [
        "iou_thresholds = [0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci-nEdUbu0X5"
      },
      "source": [
        "result_map = []\r\n",
        "for iou in iou_thresholds:\r\n",
        "  result = calculate_map(model, valid_dataloader, iou_threshold=iou, confidence_threshold=0.5)\r\n",
        "  print(\"iou_threshold:\"+ str(iou) + \" MAP: \" + str(result))\r\n",
        "  result_map.append(iou)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1szQ3uY5_4Bo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}